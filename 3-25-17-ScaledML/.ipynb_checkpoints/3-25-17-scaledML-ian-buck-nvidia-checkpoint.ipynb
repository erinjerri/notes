{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ian Buck (NVIDIA) Scaled Machine Learning on NVIDIA GPUs\n",
    "* Timeline infographic: Decade of GPU Computing - 1997-2017\n",
    "* '97 - Stream Processing @ Stanford F\n",
    "* '09 - Fermi: World's First HPC GPU \n",
    "* ImgNet and on\n",
    "\n",
    "### The end of Moore's Law\n",
    "* 40 years of Microprocessor Trend Data - 1970-2020\n",
    "* Adding on Caches, fetching blahblabhalh, complex hardware scalars\n",
    "* Transistors - tails off, only so much you can do on hardware to improve software perf. Powerwall. What's left to do? Parallel. # of logical cores added. \n",
    "\n",
    "### Graphic: Recent trends, 2004 Stanford Brook presentation. \n",
    "* GFlops Nvidia v, Pentium 4. Nvidia speeding it up.\n",
    "\n",
    "### GPU history\n",
    "* Translating Transistors into performance\n",
    "\n",
    "### What Nvidia GEFORCE 8800 GTX is doing on gaming\n",
    "* Angle surface, normals, bumpmap. Calculate what colors are, modualte light color with skin color. Produce soft tone on the way out. 100-250 instructors. GPU runs that on every pixel, IM pixels in a screen 16/sec. Running basic millsions of prallel equations at the same time. Start over and do it again.\n",
    "\n",
    "### First published paper using GPUs for AI\n",
    "* Stanford and MSR 2005\n",
    "* Using GPUs for Machine learning\n",
    "* Porting 2layer neural network \n",
    "* using directX and C#\n",
    "* these were hacks to do linear algebra \n",
    "\n",
    "### Ian's Stanford CS PhD thesis in 2003 - Brook (2003)\n",
    "\n",
    "C with sreams\n",
    "collections of records requiring similar computation\n",
    "\n",
    "particle positions, voxels, FEM cell,....\n",
    "    Ray r<200>\n",
    "    flat3 velocityfield<100, 010,100>;\n",
    "\n",
    "similar to arrays, but..\n",
    "    index oeprations disallowed: position(i)\n",
    "    read/write stream operators:\n",
    "        streamRead(positions, p_ptr);\n",
    "        streamWrite (velocityfield, v_ptr);\n",
    "    \n",
    "### CUDA: C on the GPU\n",
    "* A simple, expclity programming langauge solution\n",
    "   \n",
    "* Extend ony where necessary\n",
    "   _global_, _shared__\n",
    "   cudaMallloc(), cudaFree()\n",
    "   \n",
    "* Threading in a data parallel world\n",
    "\n",
    "KernelFunc<<< 500, 128 >>> (...);\n",
    "\n",
    "same idea of function call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda C introduced in 2006\n",
    "[Link] (http://wwww.developer.nvidia.com/cuda-toolkit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA: Threading in Data Parallel\n",
    "    // no new language, adopted for existing languages \n",
    "    \n",
    "    * Threading in a data paralell world \n",
    "    * Operations drive execution, not data\n",
    "    \n",
    "    * Users simply given thread id\n",
    "    \n",
    "    * They decide what thread access which data elem\n",
    "    * One thread - single data \n",
    "    \n",
    "### Removing divergence pain from parallel programming - infographic\n",
    "    * Single Instruction Multiple Data SIMD\n",
    "    * SIMT - Single Instruction Multiple Thread\n",
    "    \n",
    "    MIMD (Multiple Instruction Data Data)\n",
    "    SIMT = MIMD Progrmaming Model w/ SIMD Implementation Efficiencies\n",
    "    // GPUs provide benefits of both. Every thread does its own thing. keeping threads executing in parallel. \n",
    "    \n",
    "### SIMT: Eliminates fully predicated vectors\n",
    "* Slide courtesy of Andre Glew. \"Coherent Threading\" Berkeley ParLab Preso.\n",
    "* Managing divercngece becomes and optimization rather than a requirement. \n",
    "\n",
    "### Nvidia Tesla P100\n",
    "* Not typical gaming process card.\n",
    "* Pascal Architecutre, Highest Computer Perforamnce. NVLink. GPU Interactconnect for Max \n",
    "* Scalability. CoWOS HBM2. Unifying Compute and Memory in Single Package. \n",
    "* Page Migration Engine. Simple Parallel Programming w/ Virtual Unlimited Memory Space. \n",
    "* Used for HPC and AI\n",
    "\n",
    "### CUDNN: Scaling w/in a GPU\n",
    "* Stateless, Layer API for training frameworks\n",
    "\n",
    "### How do we achieve performance \n",
    "* hella math calc\n",
    "* FP32 winograd kereal across many data types\n",
    "\n",
    "### CUDNN: Accelrating frameworks\n",
    "* Apps inclusive of TF + more!\n",
    "* Scaling w/ P100\n",
    "\n",
    "### Leveraging NVLink for linear scability\n",
    "* The specs\n",
    "* Googlenet Training\n",
    "* Linear Scaling w P100s\n",
    "* Dual Xeon E5 (40 core CPU), tesla K80s, P100s PCle, cuDNN 6.06. NCLL 1.61 Training perf batch size 128 per GPU I inf perfmance w/ Tensort RT\n",
    "\n",
    "### Scaling to 8 GPUs\n",
    "* 16GB /sec - bandwidth\n",
    "* 700GB/sec - GPU memory\n",
    "* big gap bw speeds bw GPU and GPU memory itself \n",
    "\n",
    "### NVLINK - high speed interconnect bus for GPU communication\n",
    "* supports 80GB/sec - bandwidth\n",
    "* Bldg block is x8 w/ 16 wires in each dir\n",
    "* More specs...\n",
    "    \n",
    "### NCCL Collectives Lib\n",
    "    * Optmized of exchanging data bw GPUs\n",
    "    * Includes al redcue..;\n",
    "    \n",
    "### Nvidia DGX-1 \n",
    "    * DL supercomputer\n",
    "    * 250 servers in a box \n",
    "    [Link] (http://www.nvidia.com/dgx1)\n",
    "    \n",
    "### Fun Use cases\n",
    "* Pinterest recommendations \n",
    "* Weed separating at harvast, reduce chemical waste\n",
    "* Find your kid \n",
    "* Skype \n",
    "* Children's hospital of LA - predicting sick baby's vitals like  heart rate, blood pressure, survival rate \n",
    "* Microsft - enable blind to see surrnding, read emotions on faces \n",
    "* Self-driving cars \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
